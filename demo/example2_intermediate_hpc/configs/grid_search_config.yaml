# Grid Search Configuration for HPC Hyperparameter Optimization
# This configuration demonstrates systematic parameter exploration for research-grade experiments

experiment_name: "hpc_hyperparameter_grid_search"
description: "Comprehensive hyperparameter optimization on HPC cluster"

# Base model configuration for transformer architecture
model:
  name: "transformer"
  hidden_size: 512          # Will be varied in grid search
  num_layers: 6             # Will be varied in grid search
  num_heads: 8              # Will be varied in grid search
  dropout_rate: 0.1
  attention_dropout: 0.1
  layer_norm_eps: 1e-6
  max_position_embeddings: 2048

# Training configuration optimized for HPC
training:
  epochs: 100               # Longer training for thorough evaluation
  batch_size: 64            # Will be varied in grid search
  learning_rate: 1e-3       # Will be varied in grid search
  gradient_accumulation_steps: 1  # Will be varied in grid search
  gradient_clip_norm: 1.0
  warmup_ratio: 0.1
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  logging_steps: 100
  dataloader_drop_last: true

# Dataset configuration
data:
  dataset_name: "research_dataset"
  train_split: "train"
  val_split: "validation"
  test_split: "test"
  preprocessing: "standard"
  tokenizer_name: "bert-base-uncased"
  max_length: 512
  num_workers: 8
  pin_memory: true

# Optimizer configuration
optimizer:
  name: "adamw"
  weight_decay: 0.01        # Will be varied in grid search
  betas: [0.9, 0.999]
  eps: 1e-8
  amsgrad: false

# Learning rate scheduler
scheduler:
  name: "cosine"
  warmup_steps: 1000        # Will be varied in grid search
  min_lr: 1e-6
  num_cycles: 0.5

# SLURM configuration for HPC submission
slurm:
  job_name: "hparam_grid"
  time_limit: "24:00:00"    # Will be adjusted based on model size
  nodes: 1
  ntasks_per_node: 1
  cpus_per_task: 8          # Will be adjusted for larger models
  mem: "32G"               # Will be adjusted based on model size
  gres: "gpu:1"
  partition: "gpu"
  # account: "your_account"  # Uncomment and set your account
  # constraint: "v100"       # Uncomment to request specific GPU type

# Logging and experiment tracking
logging:
  log_level: "INFO"
  use_wandb: true
  wandb_project: "hpc_hyperparameter_optimization"
  # wandb_entity: "your_team"  # Uncomment and set your team
  wandb_tags: ["hpc", "grid_search", "hyperparameter_optimization"]
  log_interval: 50
  save_logs: true

# Checkpointing configuration
checkpoint:
  save_every_n_epochs: 10
  save_best_only: true
  monitor: "val_loss"
  mode: "min"
  checkpoint_dir: "./hpc_checkpoints"
  async_save: true

# Early stopping to prevent overfitting and save compute
early_stopping:
  enabled: true
  patience: 15              # Wait 15 epochs for improvement
  min_delta: 0.001          # Minimum improvement threshold
  monitor: "val_loss"
  mode: "min"

# Performance optimization
performance:
  mixed_precision: true     # Use automatic mixed precision
  compile_model: false      # PyTorch 2.0 compilation (experimental)
  dataloader_num_workers: 8
  pin_memory: true
  persistent_workers: true

# Resource monitoring
monitoring:
  track_gpu_memory: true
  track_cpu_usage: true
  log_system_stats: true
  profile_training: false   # Enable for detailed profiling

# Grid search parameters (these will be overridden by the grid search script)
grid_search:
  # Learning rate and optimization parameters
  learning_rates: [1e-4, 3e-4, 1e-3, 3e-3]
  weight_decays: [0.001, 0.01, 0.1]
  gradient_accumulation_steps: [1, 2, 4]
  warmup_steps: [500, 1000, 2000]

  # Model architecture parameters
  hidden_sizes: [256, 512, 768, 1024]
  num_layers: [4, 6, 8, 12]
  num_heads: [8, 12, 16]
  dropout_rates: [0.0, 0.1, 0.2]

  # Training parameters
  batch_sizes: [32, 64, 128]
  epochs: [50, 100, 150]
  gradient_clip_norms: [0.5, 1.0, 2.0]

# Resource allocation based on model size
resource_scaling:
  # Memory requirements (GB) based on hidden size
  memory_scaling:
    256: 16
    512: 32
    768: 48
    1024: 64
    1536: 96

  # Time limits based on model complexity
  time_scaling:
    small: "24:00:00"   # hidden_size <= 512
    medium: "36:00:00"  # 512 < hidden_size <= 1024
    large: "48:00:00"   # hidden_size > 1024

  # CPU allocation based on model size
  cpu_scaling:
    small: 8
    medium: 12
    large: 16
