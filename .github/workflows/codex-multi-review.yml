name: codex-multi-review

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
  issue_comment:
    types: [created]
  workflow_dispatch:
    inputs:
      runner_labels:
        description: "JSON array for runs-on. Examples: [\"ubuntu-latest\"] (GitHub-hosted), [\"self-hosted\",\"linux\"] (self-hosted Linux), [\"self-hosted\",\"macOS\"] (self-hosted macOS)"
        type: string
        required: false
        default: "[\"self-hosted\"]"
      use_self_hosted:
        description: "If true and runner_labels empty, use 'self-hosted'"
        type: boolean
        required: false
        default: true

permissions:
  contents: write
  pull-requests: write
  statuses: write
  issues: write

concurrency:
  group: codex-multi-review-${{ github.event.pull_request.number || github.event.issue.number || github.ref }}
  cancel-in-progress: true

jobs:
  run:
    runs-on: ${{ inputs.runner_labels && fromJSON(inputs.runner_labels) || 'self-hosted' }}
    timeout-minutes: 60
    env:
      CODEX_REASONING_EFFORT: high
      DEBUG_SNIPPET_CHARS: "4000"
      IS_SELF_HOSTED: ${{ github.event_name != 'workflow_dispatch' || (inputs.runner_labels && contains(fromJSON(inputs.runner_labels), 'self-hosted')) }}

    steps:
      - name: Detect context (PR vs comment)
        id: ctx
        run: |
          if [ "${{ github.event_name }}" = "issue_comment" ]; then
            echo "is_comment=true" >> $GITHUB_OUTPUT
          else
            echo "is_comment=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Cache npm
        if: env.IS_SELF_HOSTED != 'true'
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-cache-codex-cli-v1
          restore-keys: |
            ${{ runner.os }}-npm-cache-

      - name: Runner info
        run: |
          echo "Runner OS: ${{ runner.os }}"
          echo "Runner Arch: $(uname -m 2>/dev/null || echo unknown)"
          echo "Shell: $SHELL"

      - name: Install Codex CLI (prefer local 'codex')
        run: |
          set -e
          if command -v codex >/dev/null 2>&1; then
            CODEX_CMD="codex"
          else
            CODEX_CMD="npx -y @openai/codex"
          fi
          if $CODEX_CMD --version >/dev/null 2>&1; then
            echo "CLI_AVAILABLE=true" >> $GITHUB_ENV
            echo "CODEX_CMD=$CODEX_CMD" >> $GITHUB_ENV
            $CODEX_CMD --version || true
          else
            echo "CLI_AVAILABLE=false" >> $GITHUB_ENV
            echo "CODEX_CMD=$CODEX_CMD" >> $GITHUB_ENV
            echo "Codex CLI unavailable; reviewers will be skipped." >&2
          fi

      - name: Secrets check
        id: secrets_check
        run: | # pragma: allowlist secret
          # pragma: allowlist secret
          if [ -z "${{ secrets.CODEX_AUTH_B64 }}" ]; then
            echo "has_secrets=false" >> $GITHUB_OUTPUT # pragma: allowlist secret
          else
            echo "has_secrets=true" >> $GITHUB_OUTPUT # pragma: allowlist secret
          fi

      - name: Early exit w/ notice if no secrets
        if: steps.secrets_check.outputs.has_secrets != 'true' && github.event_name != 'workflow_dispatch' # pragma: allowlist secret
        uses: actions/github-script@v7
        with:
          script: |
            try {
              const isPR = !!context.payload.pull_request || !!context.payload.issue?.pull_request;
              if (!isPR) return;
              const issue_number = context.payload.pull_request?.number ?? context.payload.issue.number;
              await github.rest.issues.createComment({
                owner: context.repo.owner, repo: context.repo.repo,
                issue_number,
                body: "Codex review skipped: missing `CODEX_AUTH_B64` (likely a fork). A maintainer can run via **Actions → codex-multi-review → Run workflow**."
              });
            } catch (e) {
              core.warning(`Skip notice failed: ${e.status || ''} ${e.message}`);
            }

      - name: Prepare Codex
        if: steps.secrets_check.outputs.has_secrets == 'true' && env.IS_SELF_HOSTED != 'true' # pragma: allowlist secret
        env:
          CODEX_AUTH_B64: ${{ secrets.CODEX_AUTH_B64 }}
        run: |
          mkdir -p ~/.codex
          python - <<'PY'
          import os, base64
          data = base64.b64decode(os.environ['CODEX_AUTH_B64'])
          p = os.path.expanduser('~/.codex/auth.json')
          with open(p,'wb') as f:
              f.write(data)
          PY
          printf 'preferred_auth_method = "chatgpt"\n' >> ~/.codex/config.toml
          printf 'reasoning_effort = "high"\n' >> ~/.codex/config.toml

      # -------- Parse user commands (issue_comment) ----------
      - name: Parse commands (comment)
        id: cmd
        if: steps.ctx.outputs.is_comment == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const body = (context.payload.comment.body || "").trim();
            const assoc = context.payload.comment.author_association; // OWNER, MEMBER, COLLABORATOR, CONTRIBUTOR, NONE
            const isPR = !!context.payload.issue?.pull_request;
            function allow() {
              return isPR && ['OWNER','MEMBER','COLLABORATOR'].includes(assoc) ||
                     (assoc === 'CONTRIBUTOR' && context.payload.issue.user?.login === context.payload.comment.user?.login);
            }
            let run=false, strict=null, scope="", hint="";
            if (isPR && allow()) {
              if (/\b\/codex\s+rerun\b/i.test(body)) run=true;
              if (/\b\/codex\s+meta\b/i.test(body)) { run=true; }
              const m = body.match(/\b\/codex\s+strict\s+(on|off)\b/i); if (m) { run=true; strict=m[1].toLowerCase(); }
              const s = body.match(/\b\/codex\s+scope\s+(.+)\b/i); if (s) { run=true; scope=s[1].trim(); }
              if (/@codex/i.test(body)) { run=true; hint = body.replace(/.*@codex/i,'').trim(); }
            }
            core.setOutput('run', run ? 'true' : 'false');
            core.setOutput('strict', strict ?? '');
            core.setOutput('scope', scope);
            core.setOutput('hint', hint);
            return { run, strict, scope, hint };

      - name: Skip if comment not a command
        if: steps.ctx.outputs.is_comment == 'true' && steps.cmd.outputs.run != 'true'
        run: echo "No codex command found; exiting."

      # -------- Establish PR context (works for both triggers) ----------
      - name: PR context
        id: prctx
        uses: actions/github-script@v7
        with:
          script: |
            let prNumber, baseRef, baseSha, headSha;
            if (context.payload.pull_request) {
              prNumber = context.payload.pull_request.number;
              baseRef = context.payload.pull_request.base.ref;
              baseSha = context.payload.pull_request.base.sha;
              headSha = context.payload.pull_request.head.sha;
            } else if (context.payload.issue && context.payload.issue.pull_request) {
              prNumber = context.payload.issue.number;
              const pr = await github.rest.pulls.get({ owner: context.repo.owner, repo: context.repo.repo, pull_number: prNumber });
              baseRef = pr.data.base.ref;
              baseSha = pr.data.base.sha;
              headSha = pr.data.head.sha;
            } else {
              // workflow_dispatch: use current branch's open PR if any
              const branch = context.ref.replace('refs/heads/','');
              const prs = await github.rest.pulls.list({ owner: context.repo.owner, repo: context.repo.repo, head: `${context.repo.owner}:${branch}`, state: 'open' });
              if (prs.data.length) {
                const pr = prs.data[0];
                prNumber = pr.number;
                baseRef = pr.base.ref;
                baseSha = pr.base.sha;
                headSha = pr.head.sha;
              }
            }
            core.setOutput('prNumber', prNumber ?? '');
            core.setOutput('baseRef', baseRef ?? '');
            core.setOutput('baseSha', baseSha ?? '');
            core.setOutput('headSha', headSha ?? '');
            return { prNumber, baseRef, baseSha, headSha };

      - name: Guard - need PR number & secrets
        if: steps.secrets_check.outputs.has_secrets != 'true' || steps.prctx.outputs.prNumber == '' # pragma: allowlist secret
        run: exit 0

      # -------- Build DIFF (scope-aware) ----------
      - name: Normalize command options
        id: opts
        env:
          IS_COMMENT: ${{ steps.ctx.outputs.is_comment }}
          STRICT_OUT: ${{ steps.cmd.outputs.strict }}
          SCOPE_OUT: ${{ steps.cmd.outputs.scope }}
          HINT_OUT: ${{ steps.cmd.outputs.hint }}
        run: |
          strict=off; scope=""; hint=""
          if [ "$IS_COMMENT" = "true" ]; then
            [ -n "$STRICT_OUT" ] && strict="$STRICT_OUT"
            [ -n "$SCOPE_OUT" ] && scope="$SCOPE_OUT"
            [ -n "$HINT_OUT" ] && hint="$HINT_OUT"
          fi
          echo "OPTS_STRICT=$strict" >> $GITHUB_ENV
          echo "OPTS_SCOPE=$scope" >> $GITHUB_ENV
          echo "OPTS_HINT=$hint" >> $GITHUB_ENV

      - name: Build diff
        env:
          BASE: ${{ steps.prctx.outputs.baseRef }}
          SCOPE: ${{ env.OPTS_SCOPE }}
        run: |
          git fetch origin "$BASE" --depth=1
          if [ -n "$SCOPE" ]; then
            # Support multiple space-separated globs as separate pathspecs
            read -r -a scopes <<< "$SCOPE"
            git diff --unified=3 --no-color "origin/$BASE"...HEAD -- "${scopes[@]}" > pr.diff || true
          else
            git diff --unified=3 --no-color "origin/$BASE"...HEAD > pr.diff
          fi
          if [ $(wc -c < pr.diff) -gt 180000 ]; then head -c 180000 pr.diff > pr.diff.limited; echo "TRUNCATED=1" >> $GITHUB_ENV; else cp pr.diff pr.diff.limited; fi

          if [ -n "$SCOPE" ]; then
            # Use the same parsed scopes for changed-files list
            git diff --name-only "origin/$BASE"...HEAD -- "${scopes[@]}" > changed_files.txt || true
          else
            git diff --name-only "origin/$BASE"...HEAD > changed_files.txt
          fi

      - name: Collect PR details and linked issues
        id: prdetails
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.prctx.outputs.prNumber }}
        with:
          script: |
            const fs = require('fs');
            const prNumber = Number(process.env.PR_NUMBER);
            if (!prNumber) { core.setOutput('written','false'); return; }
            let pr, title='', body='';
            try {
              ({ data: pr } = await github.rest.pulls.get({ owner: context.repo.owner, repo: context.repo.repo, pull_number: prNumber }));
              title = pr.title || '';
              body = pr.body || '';
            } catch (e) {
              core.warning(`PR details fetch failed: ${e.status || ''} ${e.message}`);
            }
            const issues = new Map();
            const add = (m)=>{ const n = Number(m[1]); if (Number.isInteger(n)) issues.set(n, true); };
            const re1 = /(close[sd]?|resolve[sd]?|fix(?:e[sd])?)\s+#(\d+)/ig;
            const re2 = /#(\d+)/g;
            let m;
            for (const s of [body, title]) {
              while ((m = re1.exec(s)) !== null) add(m);
              while ((m = re2.exec(s)) !== null) add(m);
            }
            const linked = [];
            for (const num of issues.keys()) {
              try {
                const { data: issue } = await github.rest.issues.get({ owner: context.repo.owner, repo: context.repo.repo, issue_number: num });
                linked.push({ number: issue.number, title: issue.title || '', body: (issue.body || '').slice(0, 4000) });
              } catch (e) {
                linked.push({ number: num, title: '', body: '' });
              }
            }
            fs.writeFileSync('pr_title.txt', title, { encoding: 'utf8' });
            fs.writeFileSync('pr_body.txt', body, { encoding: 'utf8' });
            fs.writeFileSync('linked_issues.json', JSON.stringify(linked));
            core.setOutput('written','true');

      - name: Load prompts (existence check)
        if: env.CLI_AVAILABLE == 'true'
        run: |
          for f in reviewer_correctness.md reviewer_documentation.md reviewer_performance.md reviewer_alignment.md meta_reviewer.md cleanup_policy.md; do
            test -f ".codex/$f";
          done

      - name: Write JSON extractor util
        if: env.CLI_AVAILABLE == 'true'
        run: |
          cat > extract_json.py << 'PY'
          import sys, json
          if len(sys.argv) != 3:
              sys.exit(2)
          src, dst = sys.argv[1], sys.argv[2]
          s = open(src, 'rb').read().decode('utf-8', 'ignore')
          spans = []
          ins = False
          esc = False
          depth = 0
          start = -1
          for idx, ch in enumerate(s):
              if ins:
                  if esc:
                      esc = False
                  elif ch == '\\':
                      esc = True
                  elif ch == '"':
                      ins = False
                  continue
              if ch == '"':
                  ins = True
              elif ch == '{':
                  if depth == 0:
                      start = idx
                  depth += 1
              elif ch == '}' and depth > 0:
                  depth -= 1
                  if depth == 0 and start != -1:
                      spans.append((start, idx + 1))
          best = ''
          for a, b in spans[::-1]:
              cand = s[a:b].strip()
              try:
                  json.loads(cand)
              except Exception:
                  continue
              else:
                  best = cand
                  break
          with open(dst, 'w', encoding='utf-8') as f:
              f.write(best)
          PY
          cat > json_minify.py << 'PY'
          import sys, json
          if len(sys.argv) != 3:
              print("usage: json_minify.py <in> <out>", file=sys.stderr)
              sys.exit(2)
          src, dst = sys.argv[1], sys.argv[2]
          try:
              with open(src, 'r', encoding='utf-8') as f:
                  data = json.load(f)
          except Exception as e:
              print(f"invalid json: {e}", file=sys.stderr)
              sys.exit(1)
          with open(dst, 'w', encoding='utf-8') as f:
              json.dump(data, f, separators=(',',':'))
          PY
          cat > parse_stats.py << 'PY'
          import sys, json
          src = sys.argv[1] if len(sys.argv) > 1 else 'A.out'
          clean = sys.argv[2] if len(sys.argv) > 2 else 'A.clean'
          s=open(src,'rb').read().decode('utf-8','ignore')
          ins=False; esc=False; depth=0; start=-1; spans=[]
          for i,ch in enumerate(s):
              if ins:
                  if esc: esc=False
                  elif ch=='\\': esc=True
                  elif ch=='"': ins=False
                  continue
              if ch=='"': ins=True
              elif ch=='{':
                  if depth==0: start=i
                  depth+=1
              elif ch=='}' and depth>0:
                  depth-=1
                  if depth==0 and start!=-1:
                      spans.append((start,i+1))
          print(f"spans_found={len(spans)}")
          if spans:
              a,b=spans[-1]
              print(f"selected_span=[{a},{b}) length={b-a}")
          try:
              json.loads(open(clean,'r',encoding='utf-8').read())
              print("clean_json_valid=true")
          except Exception as e:
              print("clean_json_valid=false", str(e))
          PY

      # -------- Run reviewers in parallel ----------
      - name: Reviewers A–D (parallel)
        if: env.CLI_AVAILABLE == 'true'
        env:
          BASE_SHA: ${{ steps.prctx.outputs.baseSha }}
          HEAD_SHA: ${{ steps.prctx.outputs.headSha }}
          STRICT: ${{ env.OPTS_STRICT }}
          HINT:   ${{ env.OPTS_HINT }}
        run: |
          set -euo pipefail
          # Build prompts for all reviewers first
          python - <<'PY'
          import os
          diff = open('pr.diff.limited','r',encoding='utf-8').read()
          files = open('changed_files.txt','r',encoding='utf-8').read()
          base = os.environ.get('BASE_SHA','')
          head = os.environ.get('HEAD_SHA','')
          strict = os.environ.get('STRICT','off') or 'off'
          hint = os.environ.get('HINT','')

          # A — Correctness
          a = open('.codex/reviewer_correctness.md','r',encoding='utf-8').read()
          a = (a.replace('<<PR_DIFF>>', diff)
                 .replace('<<CHANGED_FILES>>', files)
                 .replace('<<BASE_SHA>>', base)
                 .replace('<<HEAD_SHA>>', head)
                 .replace('<<STRICT>>', strict)
                 .replace('<<FOCUS_HINT>>', hint))
          open('_A.prompt','w',encoding='utf-8').write(a)

          # B — Documentation
          b = open('.codex/reviewer_documentation.md','r',encoding='utf-8').read()
          b = (b.replace('<<PR_DIFF>>', diff)
                 .replace('<<CHANGED_FILES>>', files)
                 .replace('<<BASE_SHA>>', base)
                 .replace('<<HEAD_SHA>>', head)
                 .replace('<<STRICT>>', strict)
                 .replace('<<FOCUS_HINT>>', hint))
          open('_B.prompt','w',encoding='utf-8').write(b)

          # C — Performance
          c = open('.codex/reviewer_performance.md','r',encoding='utf-8').read()
          c = (c.replace('<<PR_DIFF>>', diff)
                 .replace('<<CHANGED_FILES>>', files)
                 .replace('<<BASE_SHA>>', base)
                 .replace('<<HEAD_SHA>>', head)
                 .replace('<<STRICT>>', strict)
                 .replace('<<FOCUS_HINT>>', hint))
          open('_C.prompt','w',encoding='utf-8').write(c)

          # D — Alignment (needs PR metadata)
          pr_title = open('pr_title.txt','r',encoding='utf-8').read() if os.path.exists('pr_title.txt') else ''
          pr_body  = open('pr_body.txt','r',encoding='utf-8').read() if os.path.exists('pr_body.txt') else ''
          linked   = open('linked_issues.json','r',encoding='utf-8').read() if os.path.exists('linked_issues.json') else '[]'
          d = open('.codex/reviewer_alignment.md','r',encoding='utf-8').read()
          d = (d.replace('<<PR_DIFF>>', diff)
                 .replace('<<CHANGED_FILES>>', files)
                 .replace('<<BASE_SHA>>', base)
                 .replace('<<HEAD_SHA>>', head)
                 .replace('<<STRICT>>', strict)
                 .replace('<<FOCUS_HINT>>', hint)
                 .replace('<<PR_TITLE>>', pr_title)
                 .replace('<<PR_BODY>>', pr_body)
                 .replace('<<LINKED_ISSUES_JSON>>', linked))
          open('_D.prompt','w',encoding='utf-8').write(d)
          PY

          json_only_msg=$'\nReturn ONLY a single JSON object matching the required schema. No prose. Do NOT include code fences. Strict JSON: decision ∈ {"APPROVE","REQUEST_CHANGES","COMMENT_ONLY"}; confidence is a number 0..1 (e.g., 0.85); all arrays contain strings; no placeholders; no trailing commas; no comments. If uncertain, choose COMMENT_ONLY.'

          # Cross-platform timeout wrappers (900s) safe under 'set -u'
          maybe_timeout_900() { if command -v timeout >/dev/null 2>&1; then timeout -k 30s 900s "$@"; elif command -v gtimeout >/dev/null 2>&1; then gtimeout -k 30s 900s "$@"; else "$@"; fi; }
          maybe_timeout_900_retry() { if command -v timeout >/dev/null 2>&1; then timeout -k 30s 900s "$@"; elif command -v gtimeout >/dev/null 2>&1; then gtimeout -k 30s 900s "$@"; else "$@"; fi; }

          run_reviewer() {
            local id="$1"; shift
            local reviewer_key="$1"; shift # correctness | documentation | performance | alignment
            local prompt_file="_${id}.prompt"
            local out_file="${id}.out"
            local last_file="${id}.last"
            local clean_file="${id}.clean"
            local json_file="${id}.json"

            (
              set +e
              maybe_timeout_900 $CODEX_CMD exec --skip-git-repo-check --output-last-message "$last_file" < "$prompt_file" > "$out_file" 2>&1 || true
              echo "::group::Debug ${id}.out (first chars)"; head -c ${DEBUG_SNIPPET_CHARS} "$out_file" || true; echo; echo '::endgroup::'
              echo "::group::Debug ${id}.last (first chars)"; head -c ${DEBUG_SNIPPET_CHARS} "$last_file" || true; echo; echo '::endgroup::'
              SRC="$last_file"; [ -s "$SRC" ] || SRC="$out_file"; python extract_json.py "$SRC" "$clean_file" || true
              echo "::group::Debug ${id}.clean (first chars)"; head -c ${DEBUG_SNIPPET_CHARS} "$clean_file" || true; echo; echo '::endgroup::'
              if [ -s "$clean_file" ] && python json_minify.py "$clean_file" "$json_file" >/dev/null 2>&1; then
                true
              else
                # Retry with JSON-only instruction
                echo "$json_only_msg" >> "$prompt_file"
                maybe_timeout_900_retry $CODEX_CMD exec --skip-git-repo-check --output-last-message "$last_file" < "$prompt_file" > "$out_file" 2>&1 || true
                echo "::group::Retry Debug ${id}.out (first chars)"; head -c ${DEBUG_SNIPPET_CHARS} "$out_file" || true; echo; echo '::endgroup::'
                echo "::group::Retry Debug ${id}.last (first chars)"; head -c ${DEBUG_SNIPPET_CHARS} "$last_file" || true; echo; echo '::endgroup::'
                SRC="$last_file"; [ -s "$SRC" ] || SRC="$out_file"; python extract_json.py "$SRC" "$clean_file" || true
                echo "::group::Retry Debug ${id}.clean (first chars)"; head -c ${DEBUG_SNIPPET_CHARS} "$clean_file" || true; echo; echo '::endgroup::'
                # For A, keep the extra parse stats for diagnostics
                if [ "$id" = "A" ]; then
                  echo '::group::A.parse stats'
                  python parse_stats.py "$out_file" "$clean_file" || true
                  echo '::endgroup::'
                fi
                if [ -s "$clean_file" ] && python json_minify.py "$clean_file" "$json_file" >/dev/null 2>&1; then
                  true
                else
                  printf '{"reviewer":"%s","decision":"COMMENT_ONLY","confidence":0.5,"summary":"Model returned no valid JSON; defaulting to COMMENT_ONLY.","strengths":[],"weaknesses":[],"required_changes":[],"suggested_changes":[],"inline_suggestions":[],"citations":[]}' "$reviewer_key" > "$json_file"
                fi
              fi
            ) &
          }

          run_reviewer A correctness
          run_reviewer B documentation
          run_reviewer C performance
          run_reviewer D alignment
          wait

      - name: Meta Reviewer
        if: env.CLI_AVAILABLE == 'true'
        env:
          BASE_SHA: ${{ steps.prctx.outputs.baseSha }}
          HEAD_SHA: ${{ steps.prctx.outputs.headSha }}
        run: |
          python - <<'PY'
          import os, json
          tmpl = open('.codex/meta_reviewer.md','r',encoding='utf-8').read()
          def read_or_default(path):
              try:
                  s = open(path,'r',encoding='utf-8').read().strip()
                  return s if s else '{}'
              except Exception:
                  return '{}'
          r1 = read_or_default('A.json')
          r2 = read_or_default('B.json')
          r3 = read_or_default('C.json')
          tmpl = (tmpl
            .replace('<<BASE_SHA>>', os.environ.get('BASE_SHA',''))
            .replace('<<HEAD_SHA>>', os.environ.get('HEAD_SHA',''))
            .replace('<<R1_JSON>>', r1)
            .replace('<<R2_JSON>>', r2)
            .replace('<<R3_JSON>>', r3))
          open('_META.prompt','w',encoding='utf-8').write(tmpl)
          PY
          maybe_timeout_900() { if command -v timeout >/dev/null 2>&1; then timeout -k 30s 900s "$@"; elif command -v gtimeout >/dev/null 2>&1; then gtimeout -k 30s 900s "$@"; else "$@"; fi; }
          maybe_timeout_900 $CODEX_CMD exec --skip-git-repo-check --output-last-message META.last < _META.prompt > META.out || true
          echo '::group::Debug META.out (first chars)'
          head -c ${DEBUG_SNIPPET_CHARS} META.out || true; echo; echo '::endgroup::'
          echo '::group::Debug META.last (first chars)'
          head -c ${DEBUG_SNIPPET_CHARS} META.last || true; echo; echo '::endgroup::'
          SRC=META.last; [ -s "$SRC" ] || SRC=META.out; python extract_json.py "$SRC" META.clean || true
          echo '::group::Debug META.clean (first chars)'
          head -c ${DEBUG_SNIPPET_CHARS} META.clean || true; echo; echo '::endgroup::'
          if [ -s META.clean ] && python json_minify.py META.clean META.json >/dev/null 2>&1; then true; else echo '{}' > META.json; fi

      # -------- Find (or create) our comment; delete older Codex comments only ----------
      - name: List comments
        id: comments
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.prctx.outputs.prNumber }}
        with:
          script: |
            const prNumber = Number(process.env.PR_NUMBER);
            try {
              const { data } = await github.rest.issues.listComments({ owner: context.repo.owner, repo: context.repo.repo, issue_number: prNumber, per_page: 100 });
              return { comments: data };
            } catch (e) {
              core.warning(`List comments failed: ${e.status || ''} ${e.message}`);
              return { comments: [] };
            }

      - name: Select comment to update and cleanup IDs
        id: select_comment
        run: |
          # Use a quoted heredoc to safely write JSON with arbitrary content
          cat > comments.json <<'JSON'
          ${{ steps.comments.outputs.result }}
          JSON
          python - <<'PY'
          import json, os
          data = json.load(open('comments.json','r',encoding='utf-8'))
          comments = data.get('comments', []) or []
          bots = [c for c in comments if c.get('user',{}).get('login') == 'github-actions[bot]']
          mine = [c for c in bots if '<!-- codex-review -->' in (c.get('body') or '')]
          mine.sort(key=lambda c: c.get('created_at',''))
          cid = str(mine[-1]['id']) if mine else ''
          del_ids = [c['id'] for c in mine if str(c.get('id')) != cid]
          with open(os.environ['GITHUB_OUTPUT'],'a',encoding='utf-8') as f:
              f.write(f"cid={cid}\n")
              import json as _j
              f.write(f"del={_j.dumps(del_ids)}\n")
          PY

      - name: Compose body
        if: env.CLI_AVAILABLE == 'true'
        id: compose
        env:
          HEAD_SHA: ${{ steps.prctx.outputs.headSha }}
          STRICT: ${{ env.OPTS_STRICT }}
          SCOPE:  ${{ env.OPTS_SCOPE }}
        run: |
          python - <<'PY'
          import os, json, sys
          def short_sha(s):
              return (s or '')[:7]
          def bullets(arr):
              arr = arr or []
              if not arr:
                  return "_none_"
              return "\n".join(f"- {x}" for x in arr)
          def cites(cites):
              cites = cites or []
              if not cites:
                  return "_none_"
              def one(c):
                  file = c.get('file') or '?'
                  lines = c.get('lines')
                  suffix = f":{lines}" if lines else ''
                  reason = c.get('reason') or ''
                  return f"- {file}{suffix} — {reason}"
              return "\n".join(one(c) for c in cites)
          def inline_suggestions(sugs):
              sugs = sugs or []
              md = "\n\n".join([ (s.get('suggestion_markdown') or '') for s in sugs ])
              return md if md.strip() else "_none_"
          def make_md(title, path):
              try:
                  with open(path,'r',encoding='utf-8') as f:
                      d = json.load(f)
              except Exception:
                  d = {}
              lines = []
              lines.append(f"#### {title}")
              lines.append(f"*Decision:* {d.get('decision','N/A')}  ")
              lines.append(f"*Confidence:* {d.get('confidence','N/A')}")
              lines.append("")
              lines.append("**Summary**")
              lines.append(d.get('summary') or "_none_")
              lines.append("")
              lines.append("**Strengths**")
              lines.append(bullets(d.get('strengths')))
              lines.append("")
              lines.append("**Weaknesses**")
              lines.append(bullets(d.get('weaknesses')))
              lines.append("")
              lines.append("**Required changes**")
              lines.append(bullets(d.get('required_changes')))
              lines.append("")
              lines.append("**Suggested changes**")
              lines.append(bullets(d.get('suggested_changes')))
              lines.append("")
              lines.append("**Inline suggestions (selected)**")
              lines.append(inline_suggestions(d.get('inline_suggestions')))
              lines.append("")
              lines.append("**Citations**")
              lines.append(cites(d.get('citations')))
              return "\n".join(lines)

          head = os.environ.get('HEAD_SHA','')
          strict = os.environ.get('STRICT','off') or 'off'
          scope = os.environ.get('SCOPE','')
          header = "<!-- codex-review -->\n" + f"[# codex-review | Commit: {short_sha(head)} | strict:{strict} | scope:\"{scope}\" ]\n\n"
          body = [header]
          body.append(make_md('Reviewer A — Correctness & Safety', 'A.json'))
          body.append("")
          body.append(make_md('Reviewer B — Documentation & DX', 'B.json'))
          body.append("")
          body.append(make_md('Reviewer C — Performance & Architecture', 'C.json'))
          body.append("")
          body.append(make_md('Reviewer D — Spec Alignment & Traceability', 'D.json'))
          body.append("")

          meta = None
          if os.path.exists('META.json'):
              try:
                  with open('META.json','r',encoding='utf-8') as f:
                      meta = json.load(f)
              except Exception:
                  meta = None
          if meta and str(meta.get('overall_score','')) != '':
              body.append('---\n\n**Meta Reviewer Scorecard**\n')
              r = meta.get('rubric') or {}
              table = [
                  "| Category | Score |",
                  "|---|---|",
                  f"| Correctness | {r.get('correctness','')} |",
                  f"| Clarity/Docs | {r.get('clarity_docs','')} |",
                  f"| Reproducibility | {r.get('reproducibility','')} |",
                  f"| Performance/Scalability | {r.get('performance_scalability','')} |",
                  f"| Security/Privacy | {r.get('security_privacy','')} |",
                  "",
                  f"**Overall:** {meta.get('overall_score','')} / 10  ",
                  f"*Meta decision:* {meta.get('meta_decision','')}  ",
                  f"*Confidence:* {meta.get('confidence','')}",
                  "",
                  "**Summary**",
                  meta.get('summary','')
              ]
              body.append("\n".join(table))
              tb = meta.get('top_blockers') or []
              if tb:
                  body.append("\n**Top blockers**\n" + "\n".join(f"- {x}" for x in tb))

          if os.environ.get('TRUNCATED'):
              body.append('\n> 🔎 Diff truncated for context. Use `/codex scope <glob>` to focus.')

          out = "\n".join(body)
          with open(os.environ['GITHUB_OUTPUT'],'a',encoding='utf-8') as f:
              f.write('body<<__CODEX_EOF__\n')
              f.write(out)
              f.write('\n__CODEX_EOF__\n')
          PY

      - name: Delete older Codex comments (safe)
        if: steps.select_comment.outputs.del != '[]'
        uses: actions/github-script@v7
        with:
          script: |
            try {
              const ids = JSON.parse(`${{ steps.select_comment.outputs.del }}`);
              for (const id of ids) {
                try {
                  await github.rest.issues.deleteComment({ owner: context.repo.owner, repo: context.repo.repo, comment_id: id });
                } catch (e) { core.warning(`Cleanup failed for ${id}: ${e.message}`); }
              }
            } catch (e) {
              core.warning(`Comment cleanup list parse failed: ${e.status || ''} ${e.message}`);
            }

      - name: Upsert Codex comment
        if: env.CLI_AVAILABLE == 'true'
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.prctx.outputs.prNumber }}
        with:
          script: |
            try {
              const prNumber = Number(process.env.PR_NUMBER);
              const cid = `${{ steps.select_comment.outputs.cid }}`;
              if (cid) {
                await github.rest.issues.updateComment({ owner: context.repo.owner, repo: context.repo.repo, comment_id: Number(cid), body: ${{ toJSON(steps.compose.outputs.body) }} });
              } else {
                await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: prNumber, body: ${{ toJSON(steps.compose.outputs.body) }} });
              }
            } catch (e) {
              core.warning(`Upsert comment failed: ${e.status || ''} ${e.message}`);
            }

      - name: Compose skip body (CLI unavailable)
        if: env.CLI_AVAILABLE != 'true'
        id: compose_skip
        env:
          HEAD_SHA: ${{ steps.prctx.outputs.headSha }}
          STRICT: ${{ env.OPTS_STRICT }}
          SCOPE:  ${{ env.OPTS_SCOPE }}
        run: |
          SHORT=$(echo "${HEAD_SHA}" | cut -c1-7)
          HEADER="<!-- codex-review -->"$'\n'"[# codex-review | Commit: ${SHORT} | strict:${STRICT:-off} | scope:\"${SCOPE}\" ]"$'\n\n'
          NOTE="Codex review skipped: Codex CLI unavailable on runner (npm install failed). Try Re-run jobs or /codex rerun later."
          {
            echo "body<<__CODEX_EOF__"
            printf "%s" "$HEADER$NOTE"
            echo
            echo "__CODEX_EOF__"
          } >> $GITHUB_OUTPUT

      - name: Upsert Codex comment (skip path)
        if: env.CLI_AVAILABLE != 'true'
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.prctx.outputs.prNumber }}
        with:
          script: |
            try {
              const prNumber = Number(process.env.PR_NUMBER);
              const cid = `${{ steps.select_comment.outputs.cid }}`;
              if (cid) {
                await github.rest.issues.updateComment({ owner: context.repo.owner, repo: context.repo.repo, comment_id: Number(cid), body: ${{ toJSON(steps.compose_skip.outputs.body) }} });
              } else {
                await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: prNumber, body: ${{ toJSON(steps.compose_skip.outputs.body) }} });
              }
            } catch (e) {
              core.warning(`Upsert comment (skip) failed: ${e.status || ''} ${e.message}`);
            }

      - name: Commit status (neutral visibility)
        uses: actions/github-script@v7
        with:
          script: |
            try {
              await github.rest.repos.createCommitStatus({
                owner: context.repo.owner, repo: context.repo.repo,
                sha: `${{ steps.prctx.outputs.headSha }}`,
                state: 'success', context: 'codex/review',
                description: 'Codex review posted'
              });
            } catch (e) {
              core.warning(`Commit status failed: ${e.status || ''} ${e.message}`);
            }

      - name: Upload artifacts
        if: env.CLI_AVAILABLE == 'true'
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: codex-multi-review-${{ github.sha }}
          path: |
            pr.diff
            pr.diff.limited
            changed_files.txt
            pr_title.txt
            pr_body.txt
            linked_issues.json
            A.json B.json C.json D.json META.json
